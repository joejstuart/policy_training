{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Policy Rule Training Pipeline\n",
        "\n",
        "This notebook combines dataset generation and model training for fine-tuning Qwen2.5-1.5B on Rego policy rules.\n",
        "\n",
        "## Steps:\n",
        "1. **Setup & Configuration** - Set paths and parameters\n",
        "2. **Generate Dataset** - Parse Rego files and create training examples\n",
        "3. **Validate Dataset** - Check dataset quality and statistics\n",
        "4. **Prepare Training** - Load and tokenize data\n",
        "5. **Train Model** - Fine-tune with LoRA\n",
        "6. **Evaluate** - Check training results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import subprocess\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "# Set tokenizers parallelism to avoid warnings\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Add current directory to path to import from generate_dataset\n",
        "sys.path.insert(0, str(Path.cwd()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "REPO_ROOT = Path.cwd().parent if Path.cwd().name == \"qwen2.5_model\" else Path.cwd()\n",
        "POLICY_RELEASE_DIR = REPO_ROOT / \"policy\" / \"release\"\n",
        "POLICY_LIB_DIR = REPO_ROOT / \"policy\" / \"lib\"\n",
        "RELEASE_LIB_DIR = REPO_ROOT / \"policy\" / \"release\" / \"lib\"\n",
        "\n",
        "# Dataset paths\n",
        "TRAIN_PATH = REPO_ROOT / \"qwen2.5_model\" / \"train.jsonl\"\n",
        "EVAL_PATH = REPO_ROOT / \"qwen2.5_model\" / \"eval.jsonl\"\n",
        "DATASET_SUMMARY_PATH = REPO_ROOT / \"qwen2.5_model\" / \"dataset_summary.json\"\n",
        "\n",
        "# Training configuration\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "OUTPUT_DIR = REPO_ROOT / \"qwen2.5-rego-policy-lora\"\n",
        "MAX_SEQ_LEN = 1024\n",
        "BATCH_SIZE = 2\n",
        "GRAD_ACCUM_STEPS = 4\n",
        "LEARNING_RATE = 5e-5\n",
        "NUM_EPOCHS = 3\n",
        "LORA_R = 16\n",
        "LORA_ALPHA = 32\n",
        "LORA_DROPOUT = 0.05\n",
        "\n",
        "# Dataset generation settings\n",
        "TRAIN_SPLIT = 0.9  # 90% train, 10% eval\n",
        "MAX_TOKENS = 1024\n",
        "\n",
        "print(f\"Repository root: {REPO_ROOT}\")\n",
        "print(f\"Policy release dir: {POLICY_RELEASE_DIR}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Dataset\n",
        "\n",
        "Import the dataset generation functions and run them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import dataset generation functions\n",
        "# Note: You may need to adjust the import path based on your setup\n",
        "try:\n",
        "    from generate_dataset import (\n",
        "        parse_rego_files,\n",
        "        generate_training_examples,\n",
        "        validate_rego_code,\n",
        "        split_train_eval,\n",
        "        write_jsonl,\n",
        "        RuleExample,\n",
        "        RegoFile\n",
        "    )\n",
        "    print(\"✓ Dataset generation functions imported\")\n",
        "except ImportError:\n",
        "    print(\"⚠ Could not import from generate_dataset.py\")\n",
        "    print(\"  Make sure you're running from the qwen2.5_model directory\")\n",
        "    print(\"  Or adjust the import path above\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse all Rego files\n",
        "print(\"Parsing Rego files...\")\n",
        "rego_files = parse_rego_files(POLICY_RELEASE_DIR)\n",
        "print(f\"✓ Parsed {len(rego_files)} Rego files\")\n",
        "\n",
        "# Show some statistics\n",
        "total_rules = sum(len(f.rules) for f in rego_files)\n",
        "print(f\"  Total rules found: {total_rules}\")\n",
        "\n",
        "# Show packages\n",
        "packages = set(f.package for f in rego_files)\n",
        "print(f\"  Packages: {len(packages)}\")\n",
        "print(f\"  Sample packages: {list(packages)[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate training examples\n",
        "print(\"Generating training examples...\")\n",
        "examples = []\n",
        "\n",
        "for rego_file in rego_files:\n",
        "    file_examples = generate_training_examples(rego_file, POLICY_LIB_DIR, RELEASE_LIB_DIR)\n",
        "    examples.extend(file_examples)\n",
        "    if len(examples) % 50 == 0:\n",
        "        print(f\"  Generated {len(examples)} examples...\")\n",
        "\n",
        "print(f\"✓ Generated {len(examples)} total examples\")\n",
        "\n",
        "# Count by task type\n",
        "task_types = defaultdict(int)\n",
        "for ex in examples:\n",
        "    task_types[ex.task_type] += 1\n",
        "print(f\"  Task types: {dict(task_types)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate examples\n",
        "print(\"Validating examples...\")\n",
        "valid_examples = []\n",
        "invalid_count = 0\n",
        "\n",
        "for i, example in enumerate(examples):\n",
        "    if i % 50 == 0:\n",
        "        print(f\"  Validated {i}/{len(examples)}...\")\n",
        "    \n",
        "    # Extract package from context\n",
        "    package = \"\"\n",
        "    if example.context:\n",
        "        match = re.search(r'package\\s+(\\S+)', example.context)\n",
        "        if match:\n",
        "            package = match.group(1)\n",
        "    \n",
        "    # Extract imports from context\n",
        "    imports = []\n",
        "    if example.context:\n",
        "        import_matches = re.findall(r'import\\s+([^\\n]+)', example.context)\n",
        "        imports = [imp.strip() for imp in import_matches]\n",
        "    \n",
        "    # Validate output code\n",
        "    is_valid, formatted_code, error_msg = validate_rego_code(\n",
        "        example.output_code,\n",
        "        package=package,\n",
        "        imports=imports\n",
        "    )\n",
        "    \n",
        "    if is_valid:\n",
        "        # Update with formatted code\n",
        "        example.output_code = formatted_code\n",
        "        valid_examples.append(example)\n",
        "    else:\n",
        "        invalid_count += 1\n",
        "        if invalid_count <= 5:  # Show first 5 errors\n",
        "            print(f\"    Invalid example: {error_msg[:100]}\")\n",
        "\n",
        "print(f\"✓ Validated: {len(valid_examples)} valid, {invalid_count} invalid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into train/eval\n",
        "train_examples, eval_examples = split_train_eval(valid_examples, TRAIN_SPLIT)\n",
        "print(f\"✓ Split: {len(train_examples)} train, {len(eval_examples)} eval\")\n",
        "\n",
        "# Write to JSONL files\n",
        "write_jsonl(train_examples, TRAIN_PATH)\n",
        "write_jsonl(eval_examples, EVAL_PATH)\n",
        "print(f\"✓ Wrote {TRAIN_PATH}\")\n",
        "print(f\"✓ Wrote {EVAL_PATH}\")\n",
        "\n",
        "# Create summary\n",
        "summary = {\n",
        "    \"total_examples\": len(valid_examples),\n",
        "    \"train_examples\": len(train_examples),\n",
        "    \"eval_examples\": len(eval_examples),\n",
        "    \"task_types\": dict(task_types),\n",
        "    \"invalid_count\": invalid_count\n",
        "}\n",
        "with open(DATASET_SUMMARY_PATH, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "print(f\"✓ Wrote {DATASET_SUMMARY_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Validate Dataset\n",
        "\n",
        "Check dataset statistics and sample examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display summary\n",
        "with open(DATASET_SUMMARY_PATH) as f:\n",
        "    summary = json.load(f)\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(json.dumps(summary, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample a few examples\n",
        "print(\"\\nSample Training Examples:\\n\")\n",
        "with open(TRAIN_PATH) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 3:  # Show first 3\n",
        "            break\n",
        "        example = json.loads(line)\n",
        "        print(f\"Example {i+1} ({example['task_type']}):\")\n",
        "        print(f\"  Instruction: {example['instruction'][:100]}...\")\n",
        "        print(f\"  Context length: {len(example.get('context', ''))} chars\")\n",
        "        print(f\"  Output code length: {len(example['output_code'])} chars\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prepare Training\n",
        "\n",
        "Load tokenizer, create dataset class, and prepare data loaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tokenizer\n",
        "print(f\"Loading tokenizer from {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(f\"✓ Tokenizer loaded (vocab size: {len(tokenizer)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# System prompt\n",
        "QWEN_SYSTEM_PROMPT = (\n",
        "    \"You are an expert Rego/OPA policy assistant. \"\n",
        "    \"You follow instructions carefully and emit valid Rego code using \"\n",
        "    \"Conforma's preferred patterns (deny contains result, METADATA, result_helper, etc). \"\n",
        "    \"Only use helpers that are provided in the context - never invent new helper functions.\"\n",
        ")\n",
        "\n",
        "def build_messages_from_example(example):\n",
        "    \"\"\"Build chat messages from policy training example.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": QWEN_SYSTEM_PROMPT}\n",
        "    ]\n",
        "    \n",
        "    # Build user message\n",
        "    user_parts = []\n",
        "    \n",
        "    if \"context\" in example:\n",
        "        user_parts.append(example[\"context\"])\n",
        "    \n",
        "    if \"instruction\" in example:\n",
        "        user_parts.append(\"\\n\" + example[\"instruction\"])\n",
        "    \n",
        "    if example.get(\"task_type\") == \"refactor\" and \"input_code\" in example:\n",
        "        user_parts.append(\"\\n\\nCode to refactor:\\n```rego\\n\" + example[\"input_code\"] + \"\\n```\")\n",
        "    \n",
        "    user_content = \"\\n\".join(user_parts)\n",
        "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "    \n",
        "    if \"output_code\" in example:\n",
        "        messages.append({\"role\": \"assistant\", \"content\": example[\"output_code\"]})\n",
        "    \n",
        "    return messages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class PolicyDataset(Dataset):\n",
        "    def __init__(self, jsonl_path, tokenizer, max_length=1024):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.examples = []\n",
        "        \n",
        "        # Load examples\n",
        "        with open(jsonl_path) as f:\n",
        "            for line in f:\n",
        "                self.examples.append(json.loads(line))\n",
        "        \n",
        "        # Pre-tokenize all examples\n",
        "        print(f\"Pre-tokenizing {len(self.examples)} examples...\")\n",
        "        self.tokenized = []\n",
        "        for i, example in enumerate(self.examples):\n",
        "            if i % 50 == 0:\n",
        "                print(f\"  Tokenized {i}/{len(self.examples)}...\")\n",
        "            \n",
        "            messages = build_messages_from_example(example)\n",
        "            text = tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=False\n",
        "            )\n",
        "            \n",
        "            encoded = tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                max_length=max_length,\n",
        "                padding=False\n",
        "            )\n",
        "            \n",
        "            self.tokenized.append({\n",
        "                \"input_ids\": encoded[\"input_ids\"],\n",
        "                \"attention_mask\": encoded[\"attention_mask\"]\n",
        "            })\n",
        "        \n",
        "        print(f\"✓ Pre-tokenization complete\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.tokenized[idx]\n",
        "\n",
        "print(\"✓ Dataset class defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "print(\"Creating training dataset...\")\n",
        "train_dataset = PolicyDataset(TRAIN_PATH, tokenizer, max_length=MAX_SEQ_LEN)\n",
        "\n",
        "print(\"\\nCreating eval dataset...\")\n",
        "eval_dataset = PolicyDataset(EVAL_PATH, tokenizer, max_length=MAX_SEQ_LEN)\n",
        "\n",
        "print(f\"\\n✓ Datasets ready:\")\n",
        "print(f\"  Train: {len(train_dataset)} examples\")\n",
        "print(f\"  Eval: {len(eval_dataset)} examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
